- name: Create a role for ec2 instance to assume to install openshift
  amazon.aws.iam_role:
    name: "{{ aws_iam_role_name }}"
    assume_role_policy_document: "{{ lookup('file','policy.json') }}"

- name: Create Installer policy and attach to the role
  amazon.aws.iam_policy:
    policy_name: openshift-install-cluster-4-18
    iam_type: role
    iam_name: "{{ aws_iam_role_name }}"
    policy_json: "{{ lookup('template', '4.18/install-cluster-policy.json') }}"
    state: present

- name: Create CCOCTL policy and attach to the role
  amazon.aws.iam_policy:
    policy_name: ccoctl-policy-4-18
    iam_type: role
    iam_name: "{{ aws_iam_role_name }}"
    policy_json: "{{ lookup('template', '4.18/ccoctl-policy.json') }}"
    state: present

- name: Create policy to Delete Cluster and attach to the role
  amazon.aws.iam_policy:
    policy_name: openshift-delete-cluster-4-18
    iam_type: role
    iam_name: "{{ aws_iam_role_name }}"
    policy_json: "{{ lookup('template', '4.18/delete-cluster-policy.json') }}"
    state: present

- name: Create ssh key pair using the given public key
  amazon.aws.ec2_key:
    name: "{{ aws_key_name }}"
    region: "{{ aws_region }}"
    key_material: "{{ ssh_public_key_for_ec2_and_openshift_node }}"
    state: present

- name: Gather Information about Connected VPC
  amazon.aws.ec2_vpc_net_info:
    filters:
      "tag:Name": "{{ aws_connected_vpc_name }}"
    region: "{{ aws_region }}"
  register: connected_vpc_info

- name: Query for any existing subnet(s) in Connected VPC
  amazon.aws.ec2_vpc_subnet_info:
    region: "{{ aws_region }}"
    filters:
      vpc-id:  "{{ connected_vpc_info.vpcs[0].vpc_id }}"
  register: connected_subnet_info

- name: Query for Private subnetID for AZ1 in Connected VPC
  amazon.aws.ec2_vpc_subnet_info:
    region: "{{ aws_region }}"
    filters:
      vpc-id:  "{{ connected_vpc_info.vpcs[0].vpc_id }}"
      "tag:Name": "{{ aws_connected_vpc_name }}-subnet-az1"
  register: connected_subnet_info_az1

- name: Query for Private subnetID for AZ2 in Connected VPC
  amazon.aws.ec2_vpc_subnet_info:
    region: "{{ aws_region }}"
    filters:
      vpc-id:  "{{ connected_vpc_info.vpcs[0].vpc_id }}"
      "tag:Name": "{{ aws_connected_vpc_name }}-subnet-az2"
  register: connected_subnet_info_az2

- name: Query for Private subnetID for AZ3 in Connected VPC
  amazon.aws.ec2_vpc_subnet_info:
    region: "{{ aws_region }}"
    filters:
      vpc-id:  "{{ connected_vpc_info.vpcs[0].vpc_id }}"
      "tag:Name": "{{ aws_connected_vpc_name }}-subnet-az3"
  register: connected_subnet_info_az3

- name: Query for Public subnetID for AZ1 in Connected VPC
  amazon.aws.ec2_vpc_subnet_info:
    region: "{{ aws_region }}"
    filters:
      vpc-id:  "{{ connected_vpc_info.vpcs[0].vpc_id }}"
      "tag:Name": "{{ aws_connected_vpc_name }}-public-subnet-az1"
  register: connected_public_subnet_info_az1

- name: Query for Public subnetID for AZ2 in Connected VPC
  amazon.aws.ec2_vpc_subnet_info:
    region: "{{ aws_region }}"
    filters:
      vpc-id:  "{{ connected_vpc_info.vpcs[0].vpc_id }}"
      "tag:Name": "{{ aws_connected_vpc_name }}-public-subnet-az2"
  register: connected_public_subnet_info_az2

- name: Query for Public subnetID for AZ3 in Connected VPC
  amazon.aws.ec2_vpc_subnet_info:
    region: "{{ aws_region }}"
    filters:
      vpc-id:  "{{ connected_vpc_info.vpcs[0].vpc_id }}"
      "tag:Name": "{{ aws_connected_vpc_name }}-public-subnet-az3"
  register: connected_public_subnet_info_az3

- name: Create DNS route53 private domain
  amazon.aws.route53_zone:
    vpc_id: "{{ connected_vpc_info.vpcs[0].vpc_id }}"
    vpc_region: "{{ aws_region }}"
    zone: "{{ openshift_cluster_name }}.{{ openshift_base_domain }}"
    state: present
  register: hosted_zone_info

- name: Create a security group for Mirror Registry to use 22,8443 and icmp
  amazon.aws.ec2_security_group:
    name: "{{ aws_security_group_for_ec2 }}"
    description: security group for Mirror Registry to use 22,8443 and icmp
    vpc_id: "{{ connected_vpc_info.vpcs[0].vpc_id }}"
    region: "{{ aws_region }}"
    rules:
      - proto: tcp
        ports:
          - 8443
          - 3128
        cidr_ip:
          - "{{ connected_vpc_info.vpcs[0].cidr_block }}"
      - proto: tcp
        ports:
          - 22
          - 5999
        cidr_ip: 0.0.0.0/0
  register: sg_info

- name: Find the latest Amazon Linux 2023 AMI ID
  amazon.aws.ec2_ami_info:
    region: "{{ aws_region }}"
    owners:
      - "amazon"
    filters:
      #name: "amzn2-ami-hvm-*-x86_64-gp2"
      name: "al2023-ami-*-kernel-6.1-x86_64"
      state: available
  register: al2023_amis

- name: Set latest_ami fact
  ansible.builtin.set_fact:
    latest_ami: "{{ al2023_amis.images | sort(attribute='creation_date', reverse=true) | first }}"

- name: Display the latest AL2023 AMI ID and Name
  ansible.builtin.debug:
    msg: "Found AMI: {{ latest_ami.name }} ({{ latest_ami.image_id }})"

- name: Launch an EC2 instance using the found AL2023 AMI
  amazon.aws.ec2_instance:
    name: "{{ aws_instance_name }}"
    region: "{{ aws_region }}"
    image_id: "{{ latest_ami.image_id }}"
    wait: yes
    network_interfaces:
      - subnet_id: "{{ connected_public_subnet_info_az1.subnets[0].id }}"
        assign_public_ip: true
    count: "{{ instance_count }}"
    instance_type: "{{ aws_instance_type }}"
    key_name: "{{ aws_key_name }}"
    vpc_subnet_id: "{{ connected_public_subnet_info_az1.subnets[0].id }}"
    security_group: "{{ aws_security_group_for_ec2 }}"
    instance_role: "{{ aws_iam_role_name }}"
    user_data: |
      #cloud-config
      hostname: "al2023-ansible-host"
      runcmd:
        - yum update -y
        - systemctl start httpd
    tags:
      Automation: "openshift_connected_installer"
    volumes:
      - device_name: /dev/sda1
        ebs:
          volume_type: gp2
          volume_size: 50
          delete_on_termination: true
  register: ec2_instance_result

- name: Wait for instance to reach 'running' state and get public IP
  amazon.aws.ec2_instance_info:
    region: "{{ aws_region }}"
    instance_ids:
      - "{{ ec2_instance_result.instance_ids[0] }}"
  register: ec2_info
  until: ec2_info.instances[0].state.name == 'running' and ec2_info.instances[0].public_ip_address is defined
  retries: 30
  delay: 10

- name: Add new instance to an in-memory inventory group
  ansible.builtin.add_host:
    name: "{{ ec2_info.instances[0].public_ip_address }}"
    groups: newly_created_ec2
    ansible_user: ec2-user
    ansible_ssh_private_key_file: "{{ ssh_private_key_file_for_ec2_and_openshift_node }}"

- name: Wait for SSH port to be open on the new instance
  ansible.builtin.wait_for:
    host: "{{ ec2_info.instances[0].public_ip_address }}"
    port: 22
    delay: 10
    timeout: 120
  delegate_to: localhost # Run this check from your control machine

- name: Add the new instance's SSH key to known_hosts
  ansible.builtin.shell:
    cmd: "ssh-keyscan -H {{ ec2_info.instances[0].public_ip_address }} >> ~/.ssh/known_hosts"
  delegate_to: localhost

- debug:
    msg: "New EC2 host: ec2-user@{{ ec2_info.instances[0].public_ip_address }}"